---
layout: single
title: "내 R&E 포스터 글 v2"
excerpt: "md 파일 적당히 넣을 데가 없어서"
classes: wide
categories: [research, ai]
tags: [research, my life, ai]
math: true
toc: false
---

<style>
    .page__content figure > figcaption {
        text-align: center !important;
        margin: -0.4rem 0 0 !important;
        padding: 0 !important;
        font-size: .95em;
        line-height: 1.35;
        background: transparent;
        border: 0;
    }
    img.center {
        display: block;
        margin-left: auto;
        margin-right: auto;
    }
    .lh-boost { line-height: 2.7; }
</style>


# Introduction

엘니뇨는 해양과 대기 간 복잡한 상호작용으로 발생하는 대표적인 전지구적 기후변화 현상으로 농업 생산성, 물 자원 분포등에 큰 영향을 미친다.  엘니뇨는 전 세계적인 기상 패턴을 교란시켜 일부 지역에는 극심한 가뭄을 다른 지역에는 파괴적인 홍수를 초래한다. 이러한 기후 이상 현상은 농업 생산성과 수산업에 피해를 주어 식량 안보를 위협한다. 또한 엘니뇨는 산불, 질병 확산, 경제적 손실의 위험을 증가시킨다. 엘니뇨는 지금까지 비선형적이고 주기가 없어 예측이 잘 되지 못하고 있어 본 연구에서는 엘니뇨를 예측하기 위해 새로운 딥러닝 모델을 만들고 예측을 시도했다.​

<br>

# Background

*   ## Transformer

    Transformer는  RNN·LSTM과 달리 순차적 처리 없이 Attention 메커니즘만을 활용해 시퀀스 내 관계를 병렬적으로 학습한다.

    <br>

    $\begin{equation}
        Attention(Q, K, V) = softmax( \frac{QK^{T}}{\sqrt{d_k}} )V  \label{eq1}
    \end{equation}$​

    <br>

    수식 $\ref{eq1}$은 Transformer 구조의 핵심적인 알고리즘인 Attention의 수식을 보여준다.
    
    이 구조는 Encoder-Decoder, Positional Encoding, Feed-Forward Networks 등으로 구성되며 긴 시퀀스에서도 장기 의존성을 효과적으로 학습할 수 있다.

*   ## Patch Embedding

    Patch Embedding은 이미지를 작은 패치 단위의 벡터로 분할하는 과정이며, Attention은 벡터의 시계열 데이터를 다루기에 Attention을 이미지 처리에 사용하기 위해서는 필수적인 과정이다.

    <br>

    $\begin{equation}
        x \in \mathbb{R}^{H \times W \times C} \rightarrow x_p \in \mathbb{R}^{N \times (P^2 \cdot C)}  \label{eq2}
    \end{equation}$

    <br>

    수식 $\ref{eq2}$에서, $x$는 원본 이미지 텐서이고, $x_p$는 Patch Embedding된 패치이다. 이는 $(H, W)$의 원본 해상도, $C$의 채널 개수, $(P, P)$ 해상도의 패치, $N=HW/P^2$일 경우의 Patch Embedding 식을 보여준다.


*   ## Vision Transformer

    Vision Transformer는 이미지의 분류 모델에 Transformer 아키텍쳐를 활용한 모델이다.

    이는 효율적인 Attention 알고리즘의 적용으로 CNN모델보다 더 높은 정확도를 보인다.

    이 구조는 Encoder, Patch Embedding, Positional Encoding와 결합한 Transformer를 이용하여 본래 단어의 처리에 사용되던 Transformer를 이미지 프로세싱에 이용할 수 있게 했다.