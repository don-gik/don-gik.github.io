---
layout: single
title: "내 R&E 포스터 글 v2"
excerpt: "md 파일 적당히 넣을 데가 없어서"
classes: wide
categories: [research, ai]
tags: [research, my life, ai]
math: true
toc: false
---

<style>
    .page__content figure > figcaption {
        text-align: center !important;
        margin: -0.4rem 0 0 !important;
        padding: 0 !important;
        font-size: .95em;
        line-height: 1.35;
        background: transparent;
        border: 0;
    }
    img.center {
        display: block;
        margin-left: auto;
        margin-right: auto;
    }
    .lh-boost { line-height: 2.7; }
</style>


# Introduction

엘니뇨는 해양과 대기 간 복잡한 상호작용으로 발생하는 대표적인 전지구적 기후변화 현상으로 농업 생산성, 물 자원 분포등에 큰 영향을 미친다.  엘니뇨는 전 세계적인 기상 패턴을 교란시켜 일부 지역에는 극심한 가뭄을 다른 지역에는 파괴적인 홍수를 초래한다. 이러한 기후 이상 현상은 농업 생산성과 수산업에 피해를 주어 식량 안보를 위협한다. 또한 엘니뇨는 산불, 질병 확산, 경제적 손실의 위험을 증가시킨다. 엘니뇨는 지금까지 비선형적이고 주기가 없어 예측이 잘 되지 못하고 있어 본 연구에서는 엘니뇨를 예측하기 위해 새로운 딥러닝 모델을 만들고 예측을 시도했다.​

<br>

# Background

*   ## Transformer

    Transformer는  RNN·LSTM과 달리 순차적 처리 없이 Attention 메커니즘만을 활용해 시퀀스 내 관계를 병렬적으로 학습한다.

    <br>

    $\begin{equation}
        Attention(Q, K, V) = softmax( \frac{QK^{T}}{\sqrt{d_k}} )V  \label{eq1}
    \end{equation}$​

    <br>

    수식 $\ref{eq1}$은 Transformer 구조의 핵심적인 알고리즘인 Attention의 수식을 보여준다.
    
    이 구조는 Encoder-Decoder, Positional Encoding, Feed-Forward Networks 등으로 구성되며 긴 시퀀스에서도 장기 의존성을 효과적으로 학습할 수 있다.

*   ## Patch Embedding

    Patch Embedding은 이미지를 작은 패치 단위의 벡터로 분할하는 과정이며, Attention은 벡터의 시계열 데이터를 다루기에 Attention을 이미지 처리에 사용하기 위해서는 필수적인 과정이다.

    <br>

    $\begin{equation}
        x \in \mathbb{R}^{H \times W \times C} \rightarrow x_p \in \mathbb{R}^{N \times (P^2 \cdot C)}  \label{eq2}
    \end{equation}$

    <br>

    수식 $\ref{eq2}$에서, $x$는 원본 이미지 텐서이고, $x_p$는 Patch Embedding된 패치이다. 이는 $(H, W)$의 원본 해상도, $C$의 채널 개수, $(P, P)$ 해상도의 패치, $N=HW/P^2$일 경우의 Patch Embedding 식을 보여준다.


*   ## Vision Transformer

    Vision Transformer는 이미지의 분류 모델에 Transformer 아키텍쳐를 활용한 모델이다.

    이는 효율적인 Attention 알고리즘의 적용으로 CNN모델보다 더 높은 정확도를 보인다.

    이 구조는 Encoder, Patch Embedding, Positional Encoding와 결합한 Transformer를 이용하여 본래 단어의 처리에 사용되던 Transformer를 이미지 프로세싱에 이용할 수 있게 했다.

<br>

# Method

*   ## Vision Transformer를 활용한 시공간 예측
    
    본 연구에서는 시공간 예측을 위해 변형된 Vision Transformer를 이용한다.

    <br>

    $\begin{equation}
        x \in \mathbb{R}^{H \times W \times T \times C} \rightarrow x_p \in \mathbb{R}^{N \times (P^2 \cdot T \cdot C)} \label{eq3}
    \end{equation}$

    <br>

    수식 $\ref{eq3}$에서, 기존 Vision Transformer의 채널에 시간 축을 포함시킴으로써 Transformer 구조를 활용하였다.

    이 변형된 구조에서는 Patch Embedding을 하기 전, Time Encoding을 거친다. 이는 Time Sequence의 학습을 개선하기 위해서 추가된 사항으로, Sinosoidal Encoding을 사용하였다.

    Patch Embedding은 기존의 ViT 모델에서의 Class Token을 제외시킨다. 이 과정에서 각 Patch에 관한 Positional Encoding이 더해지도록 하였다.

* ## 실험
    
    실험에서는 A100 GPU 1개를 이용하여 3시간 가량 학습하였다. 데이터셋은 ERA5 monthly averaged data on single levels from 1940 to present을 활용한 Nino 3.4 구역의 데이터를 사용하였다. 모델은 표면 해수온을 포함한 10개의 변수를 입력으로 받고, 이를 해상도를 유지하며 예측하였다.

    월별 평균 자료의 특성상 자료의 개수가 적기에 노이즈를 추가한 데이터셋으로 사전학습을 진행한 후, 적은 수의 데이터로 Fine Tuning 하였다.

<br>

# Result

<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-11-17-research/model-_sst_lead_point_error_physical.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>fig 1. 표면 해수온 장기예측의 오차</figcaption>
</figure>

fig. 1에서, 모델은 1년 예측에서 $0.753°C$의 RMSE 오차를 보였다. 월별 평균이 아닌 Nino Index에서는 오차가 평균되므로 RMSE 값은 $\sqrt{3}$으로 나눈 값인 $0.435°C$의 RMSE 오차를 보일 것으로 기대할 수 있다. 이는 선행연구인 Temporal Convolutional Networks의 오차인 $0.5142°C$보다 개선된 값이다.

<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-11-17-research/model-_random_physical_sample.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>fig 2. 표면 해수온 1달 예측의 시각화</figcaption>
</figure>

본 연구의 모델은 각 변수를 2차원 해상도로 예측하기 때문에 이를 시각화하고 이를 분석할 수 있다. fig 2.에서, 모델이 1달 예측에서는 우수한 성능을 보임을 알 수 있다.

<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-11-17-research/model-_per_var_errors_normalized.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>fig 3. 정규화된 각 변수의 오차</figcaption>
</figure>

fig 3.에서는 정규화된 상태에서 각 변수의 오차를 보여준다. 이는 본래 $483056 J \cdot m^{-2}$, $57.5 Pa$, $57.4 Pa$, $0.71 m/s^{2}$, $0.59 m/s^{2}$, $0.55 m/s^{2}$, $0.49 m/s^{2}$, $0.38 °C$, $0.26 °C$, $0.22 °C$의 RMSE 오차이다.

<br>

추후의 연구에서 이 모델이 예측을 할 때 어느 부분을 바라보는 경향성이 있는지 알아볼 수 있다. 이는 해당 모델이 Attentioㅜ