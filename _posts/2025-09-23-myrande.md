---
layout: single
title: "내 R&E 포스터 글"
excerpt: "md 파일 적당히 넣을 데가 없어서"
classes: wide
categories: [research]
tags: [research, my life]
math: true
toc: false
---

<style>
    .page__content figure > figcaption {
        text-align: center !important;
        margin: -0.4rem 0 0 !important;
        padding: 0 !important;
        font-size: .95em;
        line-height: 1.35;
        background: transparent;
        border: 0;
    }
    img.center {
        display: block;
        margin-left: auto;
        margin-right: auto;
    }
</style>

<h3 class ="center">
    참고
</h3>
Attention 식:
$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $


### 이 연구의 주요 내용
* Axial Attention Transformer 모델은 이 연구에서 새로 제안하는 장기 예측 모델이다.
이 모델은 각 축에 대한 Attention Feature 값을 Multi Layer Perceptron으로 연결되어있는 구조를 띄고 있는 구조이며,
잔차 연결을 이용해 값을 안정화시켰다.
잔차 연결은, 장기 예측에서도 모델이 안정적인 값을 내놓을 수 있도록 한다.

* Axial Attention Transformer는 일반적인 Transformer와 굉장히 유사하나, 시공간적인 요소를 모두 attention을 활용한다는 점에서 다르다.
Encoder는 Windowed Attention을 활용하여 만들어졌다.
Window는 모델을 경량으로 유지하면서도 공간적인 유사도를 크게 유지하게 잠재 공간에 임베딩하도록 해준다.
Decoder는 간단한 Upsampling과 Convolution Layer의 Block으로 구성되어있다.
Axial Attention 모델은 잠재 공간에서의 값들 간의 관계를 학습한다.
여러 축에서 행해지는 Attention은 더 다양한 상관관계를 학습할 수 있도록 해준다.

* 모델은 1개의 NVIDIA RTX A6000 GPU에서 6시간 동안 학습되었다.
Nino 3.4 구역의 40 x 200 격자를 예측하는 경량 모델이라고 할 수 있다.
이는 전지구 예측도 추후 연구에서 더 다뤄질 수 있음을 알려준다.

### 연구 결과

<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-09-23-research/1.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>공간관계에서 PCC 값이 높은 값을 유지하고 있음을 알 수 있다.</figcaption>
</figure>
<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-09-23-research/2.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>RMSE 값이 24 * 15일, 즉 1년 예측에서 0.59로 작은 값을 유지하고 있음을 알 수 있다.</figcaption>
</figure>

모델의 성능은 선행 ENSO 딥러닝 연구인 Temporal Convolutional Network의 성능인 RMSE 0.56과 굉장히 유사했다.
공간적 PCC의 값은 단기예측과 장기예측 모두에서 준수한 성능을 보였으며, Temporal Convolutional Network가 8-9시간의 학습을 요구한 점을 고려하면
굉장히 빠르게 값이 수렴하고 학습되는 모델이라는 점을 알 수 있다.


<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-09-23-research/3.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>Temporal Correlation값도 높은 값을 유지하고 있음을 알 수 있다.</figcaption>
</figure>
<figure class="align-center" align="center">
    <img src="{{ 'assets/images/2025-09-23-research/4.png' | relative_url }}"
    loading="lazy" decoding="async"
    style="max-width:70%; height:auto; border-radius:8px;">
    <figcaption>1년 후의 예측 결과 예시 자료</figcaption>
</figure>


가장 간단한 모델인 Persistency 모델과 비교할 경우, Axial Attention Transformer 모델이 Temporal Correlation 값을 비교했을 때 훨씬 더
값이 크다는 것을 알 수 있다. 이는 단순한 모델보다 본 연구의 모델이 훨씬 개선된 성능을 보여준다는 것을 의미한다.
RMSE값의 경우 마지막 1년 상태에서 본 연구의 모델은 0.6536, Persistency 모델은 0.8227의 성능을 보여주었으며,
이는 Skill Value가 0.37이 된다는 것을 알 수 있다.

추후의 연구에서 이 모델을 더 발전시킨다면, Encoder에서 차원을 유지하는 것이 아니라 더 늘림으로써 성능을 개선하는 새로운 방식이 탄생할 수도 있다.
최초로 고안된 모델임에도 뛰어난 성능을 가진 것은 추후 연구에서 더 보정되면서 정확도를 개선할 수 있다는 잠재 가능성을 보여준다.